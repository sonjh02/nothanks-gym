{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "me (1), other players (N-1), merged (1) //, open (1)\n",
    "card: (N+1)x33\n",
    "pot: (N+1)x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ipypb import irange\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVN(nn.Module):\n",
    "    def __init__(self, n=5):\n",
    "        super(DVN, self).__init__()\n",
    "        sz1 = (n+1)*34\n",
    "        sz2 = (n+1)*20\n",
    "        sz3 = (n+1)*10\n",
    "        sz4 = (n+1)*5\n",
    "\n",
    "        self.ds1 = nn.Linear(sz1, sz2);\n",
    "        self.bn1 = nn.BatchNorm1d(sz2, eps=1)\n",
    "        self.ds2 = nn.Linear(sz2, sz3);\n",
    "        self.bn2 = nn.BatchNorm1d(sz3, eps=1)\n",
    "        self.ds3 = nn.Linear(sz3, sz4);\n",
    "        self.bn3 = nn.BatchNorm1d(sz4, eps=1)\n",
    "        self.ds4 = nn.Linear(sz4, 1, bias=False)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.ds1.weight)\n",
    "        nn.init.xavier_normal_(self.ds2.weight)\n",
    "        nn.init.xavier_normal_(self.ds3.weight)\n",
    "        nn.init.xavier_normal_(self.ds4.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.ds1(x)))\n",
    "        x = F.relu(self.bn2(self.ds2(x)))\n",
    "        x = F.relu(self.bn3(self.ds3(x)))\n",
    "        return self.ds4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state: players (N) + merged (1) x token (1) + card (33)  \n",
    "\n",
    "N = 5\n",
    "\n",
    "def mutate(state, pot, action):\n",
    "    state, pot = state.copy(), pot.copy()\n",
    "    if state[0,0] == 0:\n",
    "        action = False\n",
    "    if action:\n",
    "        state[[0,-1],0] -= 1\n",
    "        pot[0] += 1\n",
    "    else:\n",
    "        state[0] += pot\n",
    "        state[-1] += pot\n",
    "        pot *= 0\n",
    "    return state, pot\n",
    "        \n",
    "def next_turn(state):\n",
    "    return np.r_[state[1:-1], state[0:1], state[-1:]]\n",
    "\n",
    "def to_tensor(state):\n",
    "    return torch.from_numpy(state.reshape((-1, (N+1)*34))).float().to(device)\n",
    "\n",
    "def evaluate(net, state):\n",
    "    net.eval()\n",
    "    return net(to_tensor(state)).data.cpu().numpy()[0,0]\n",
    "\n",
    "def get_score(state):\n",
    "    out = state[0,0]\n",
    "    if state[0,1] == 1: \n",
    "        out -= 3\n",
    "    for i in range(2, 34):\n",
    "        if state[0,i] == 1 and state[0,i-1] == 0:\n",
    "            out -= i + 2\n",
    "    return out\n",
    "    \n",
    "def spawn_player(value_net):\n",
    "    def player(state, pot):\n",
    "        if state[0,0] == 0: \n",
    "            return False\n",
    "        sT = mutate(state, pot, True)[0]\n",
    "        sF = mutate(state, pot, False)[0]\n",
    "        vT = evaluate(value_net, sT)\n",
    "        vF = evaluate(value_net, sF)\n",
    "        \n",
    "        # print(vT, vF)\n",
    "        return vT > vF\n",
    "    return player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn = DVN(N).to(device)\n",
    "vn.load_state_dict(torch.load('m.mdl'))\n",
    "players = [spawn_player(vn) for _ in range(N)]\n",
    "\n",
    "# vns = [DVN(N).to(device) for _ in range(N)]\n",
    "# players = [spawn_player(vn) for vn in vns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gym(players):\n",
    "    card = np.arange(33) + 3\n",
    "    \n",
    "    deck = card.copy()\n",
    "    np.random.shuffle(deck)\n",
    "    deck = list(deck[:24])\n",
    "    def draw():\n",
    "        return np.r_[0, (card.copy() == deck.pop()).astype(int)]\n",
    "\n",
    "    n = len(players)\n",
    "    state = np.r_[[np.r_[11, np.zeros((33,), int)] for _ in range(n)]]\n",
    "    state = np.r_[state, state.sum(axis=0).reshape((1, -1))]\n",
    "    \n",
    "    turn = np.random.randint(n)\n",
    "    replay = []\n",
    "    # non-terminal: is_terminal, id, state_before, state_after, reward\n",
    "    # terminal: is_terminal, id, state, score, place\n",
    "    \n",
    "    while len(deck) > 0:\n",
    "        pot = draw()\n",
    "        while True:\n",
    "            nothanks = players[turn](state, pot)\n",
    "            state_, pot_ = mutate(state, pot, nothanks)\n",
    "            reward = get_score(state_) - get_score(state)\n",
    "            replay.append((False, turn, state, state_, reward))\n",
    "            if nothanks:\n",
    "                turn = (turn + 1)%n\n",
    "                state = next_turn(state_)\n",
    "                pot = pot_\n",
    "            else:\n",
    "                state = state_\n",
    "                break\n",
    "                \n",
    "    scores = []\n",
    "    for _ in range(n):\n",
    "        scores.append(-get_score(state))\n",
    "        state = next_turn(state)\n",
    "    scores.sort()\n",
    "    for _ in range(n):\n",
    "        score = get_score(state)\n",
    "        replay.append((True, turn, state, score, scores.index(-score)))\n",
    "        state = next_turn(state)\n",
    "        turn = (turn + 1)%n\n",
    "      \n",
    "    return replay\n",
    "\n",
    "replay = gym(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(vn, replay, gamma=0.95, batch_size=64, place_value=[120, 80, 60, 40, 0], epoch=10):\n",
    "    vn.train()\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = optim.Adam(vn.parameters())\n",
    "    \n",
    "    n_replay = len(replay)\n",
    "    for _ in irange(epoch):\n",
    "        argseq = np.arange(n_replay)\n",
    "        np.random.shuffle(argseq)\n",
    "        for i in range(0, n_replay, batch_size):\n",
    "            x = []\n",
    "            y = []\n",
    "            if argseq[i:].size < batch_size:\n",
    "                break\n",
    "            for j in range(batch_size):\n",
    "                is_terminal, _, state, a, b = replay[argseq[i+j]]\n",
    "                x.append(state.flatten())\n",
    "                if is_terminal:\n",
    "                    y.append(a + place_value[b])\n",
    "                else:\n",
    "                    state_after = a\n",
    "                    reward = b\n",
    "                    y.append(reward + evaluate(vn, state_after)*gamma)\n",
    "\n",
    "            x = to_tensor(np.r_[x])\n",
    "            y = torch.from_numpy(np.r_[y].reshape((-1,1))).float().to(device)\n",
    "            prediction = vn(x)\n",
    "            loss = criterion(prediction, target=y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lineage: 1\n",
      "  player 3: #4 (-96): 54 - [6, 12, 13, 20, 24, 26, 30, 32]\n",
      "  player 4: #3 (-81): 1 - [7, 8, 19, 23, 33]\n",
      "  player 0: #5 (-132): 0 - [10, 11, 17, 22, 25, 27, 31]\n",
      "  player 1: #1 (-33): 0 - [4, 29]\n",
      "  player 2: #2 (-50): 0 - [16, 34]\n",
      "total: -392\n",
      "loss: 12.260175704956055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"128\" value=\"128\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">128/128</span>\n",
       "<span class=\"Time-label\">[00:11<00:00, 0.09s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [████████████████████████████████████████████████████████████] 128/128 [00:11<00:00, 0.09s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"10\" value=\"6\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>60%</strong></span>\n",
       "<span class=\"Iteration-label\">6/10</span>\n",
       "<span class=\"Time-label\">[01:20<00:13, 13.33s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [████████████████████████████████████########################] 6/10 [01:20<00:13, 13.33s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "replay = []\n",
    "for lineage in range(100):\n",
    "    for _ in irange(128):\n",
    "        replay += gym(players)\n",
    "    replay[-64*256:]\n",
    "    loss = train(vn, replay, batch_size=256, epoch=10)\n",
    "    torch.save(vn.state_dict(), 'm.mdl')\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    total = 0\n",
    "    print(f'lineage: {lineage}')\n",
    "    for _, idx, state, score, place in gym(players)[-N:]:\n",
    "        total += score\n",
    "        print(f'  player {idx}: #{place+1} ({score}): {state[0,0]} - [{\", \".join([f\"{i+2}\" for i in range(1,34) if state[0,i] == 1])}]')\n",
    "    print(f'total: {total}')\n",
    "    print(f'loss:', loss.data.cpu().numpy() + 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
