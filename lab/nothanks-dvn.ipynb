{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "me (1), other players (N-1), merged (1) //, open (1)\n",
    "card: (N+1)x33\n",
    "pot: (N+1)x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ipypb import irange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVN(nn.Module):\n",
    "    def __init__(self, n=5):\n",
    "        super(DVN, self).__init__()\n",
    "        in_sz = (n+1)*34\n",
    "        self.ds1 = nn.Linear(in_sz, in_sz);\n",
    "        self.bn1 = nn.BatchNorm1d(in_sz, eps=1)\n",
    "        self.ds2 = nn.Linear(in_sz, in_sz*2);\n",
    "        self.bn2 = nn.BatchNorm1d(in_sz*2, eps=1)\n",
    "        self.ds3 = nn.Linear(in_sz*2, in_sz);\n",
    "        self.bn3 = nn.BatchNorm1d(in_sz, eps=1)\n",
    "        self.ds4 = nn.Linear(in_sz, 1, bias=False)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.ds1.weight)\n",
    "        nn.init.xavier_normal_(self.ds2.weight)\n",
    "        nn.init.xavier_normal_(self.ds3.weight)\n",
    "        nn.init.xavier_normal_(self.ds4.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.ds1(x)))\n",
    "        x = F.relu(self.bn2(self.ds2(x)))\n",
    "        x = F.relu(self.bn3(self.ds3(x)))\n",
    "        return self.ds4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state: players (N) + merged (1) x token (1) + card (33)  \n",
    "\n",
    "N = 5\n",
    "\n",
    "def mutate(state, pot, action):\n",
    "    state, pot = state.copy(), pot.copy()\n",
    "    if state[0,0] == 0:\n",
    "        action = False\n",
    "    if action:\n",
    "        state[[0,-1],0] -= 1\n",
    "        pot[0] += 1\n",
    "    else:\n",
    "        state[0] += pot\n",
    "        state[-1] += pot\n",
    "        pot *= 0\n",
    "    return state, pot\n",
    "        \n",
    "def next_turn(state):\n",
    "    return np.r_[state[1:-1], state[0:1], state[-1:]]\n",
    "\n",
    "def to_tensor(state):\n",
    "    return torch.from_numpy(state.reshape((-1, (N+1)*34))).float().to(device)\n",
    "\n",
    "def evaluate(net, state):\n",
    "    net.eval()\n",
    "    return net(to_tensor(state)).data.cpu().numpy()[0,0]\n",
    "\n",
    "def score(state):\n",
    "    out = state[0,0]\n",
    "    if state[0,1] == 1: \n",
    "        out -= 3\n",
    "    for i in range(2, 34):\n",
    "        if state[0,i] == 1 and state[0,i-1] == 0:\n",
    "            out -= i + 2\n",
    "    return out\n",
    "    \n",
    "def spawn_player(value_net):\n",
    "    def player(state, pot):\n",
    "        if state[0,0] == 0: \n",
    "            return False\n",
    "        sT = mutate(state, pot, True)[0]\n",
    "        sF = mutate(state, pot, False)[0]\n",
    "        vT = evaluate(value_net, sT)\n",
    "        vF = evaluate(value_net, sF)\n",
    "        return vT > vF\n",
    "    return player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vns = [DVN(N).to(device) for _ in range(N)]\n",
    "players = [spawn_player(vn) for vn in vns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gym(players):\n",
    "    card = np.arange(33) + 3\n",
    "    \n",
    "    deck = card.copy()\n",
    "    np.random.shuffle(deck)\n",
    "    deck = list(deck[:24])\n",
    "    def draw():\n",
    "        return np.r_[0, (card.copy() == deck.pop()).astype(int)]\n",
    "\n",
    "    n = len(players)\n",
    "    state = np.r_[[np.r_[11, np.zeros((33,), int)] for _ in range(n)]]\n",
    "    state = np.r_[state, state.sum(axis=0).reshape((1, -1))]\n",
    "    \n",
    "    turn = np.random.randint(n)\n",
    "    replay = []\n",
    "    # non-terminal: is_terminal, id, state_before, state_after, reward\n",
    "    # terminal: is_terminal, id, state, score, place\n",
    "    \n",
    "    while len(deck) > 0:\n",
    "        pot = draw()\n",
    "        while True:\n",
    "            nothanks = players[turn](state, pot)\n",
    "            state_, pot_ = mutate(state, pot, nothanks)\n",
    "            reward = score(state_) - score(state)\n",
    "            replay.append((False, turn, state, state_, reward))\n",
    "            if nothanks:\n",
    "                turn = (turn + 1)%n\n",
    "                state = next_turn(state_)\n",
    "                pot = pot_\n",
    "            else:\n",
    "                state = state_\n",
    "                break\n",
    "                \n",
    "    scores = []\n",
    "    for _ in range(n):\n",
    "        scores.append(-score(state))\n",
    "        state = next_turn(state)\n",
    "    scores.sort()\n",
    "    for _ in range(n):\n",
    "        scr = score(state)\n",
    "        replay.append((True, turn, state, scr, scores.index(-scr)))\n",
    "        state = next_turn(state)\n",
    "        turn = (turn + 1)%n\n",
    "      \n",
    "    return replay\n",
    "\n",
    "replay = gym(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(vn, replay, gamma=0.95, batch_size=32, place_value=[120, 80, 60, 40, 0], epoch=10):\n",
    "    vn.train()\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = optim.Adam(vn.parameters())\n",
    "    \n",
    "    n_replay = len(replay)\n",
    "    for _ in irange(epoch):\n",
    "        argseq = np.arange(n_replay)\n",
    "        np.random.shuffle(argseq)\n",
    "        for i in range(0, n_replay, batch_size):\n",
    "            x = []\n",
    "            y = []\n",
    "            if argseq[i:].size < batch_size:\n",
    "                break\n",
    "            for j in range(batch_size):\n",
    "                is_terminal, _, state, a, b = replay[argseq[i+j]]\n",
    "                x.append(state.flatten())\n",
    "                if is_terminal:\n",
    "                    y.append(a + place_value[b])\n",
    "                else:\n",
    "                    state_after = a\n",
    "                    reward = b\n",
    "                    y.append(reward + evaluate(vn, state_after)*gamma)\n",
    "\n",
    "            x = to_tensor(np.r_[x])\n",
    "            y = torch.from_numpy(np.r_[y].reshape((-1,1))).float().to(device)\n",
    "            prediction = vn(x)\n",
    "            loss = criterion(prediction, target=y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"20\" value=\"0\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>0%</strong></span>\n",
       "<span class=\"Iteration-label\">0/20</span>\n",
       "<span class=\"Time-label\">[0<0, 0.00s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[2K\r",
       " [############################################################] 0/20 [0<0, 0.00s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"64\" value=\"64\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">64/64</span>\n",
       "<span class=\"Time-label\">[00:04<00:00, 0.07s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [████████████████████████████████████████████████████████████] 64/64 [00:04<00:00, 0.07s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"10\" value=\"5\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>50%</strong></span>\n",
       "<span class=\"Iteration-label\">5/10</span>\n",
       "<span class=\"Time-label\">[00:11<00:02, 2.26s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [██████████████████████████████##############################] 5/10 [00:11<00:02, 2.26s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-077bd821c9dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mreplay\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'm{i}.mdl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-f1af8a9322aa>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(vn, replay, gamma, batch_size, place_value, epoch)\u001b[0m\n\u001b[0;32m     21\u001b[0m                     \u001b[0mstate_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                     \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_after\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-131d4b94b503>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(net, state)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in irange(20):\n",
    "    replay = []\n",
    "    for _ in irange(64):\n",
    "        replay += gym(players)\n",
    "    for i in range(5):\n",
    "        train(vns[i], replay)\n",
    "        torch.save(vns[i].state_dict(), f'm{i}.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player 0: #5 (-158)\n",
      "player 1: #1 (4)\n",
      "player 2: #3 (-47)\n",
      "player 3: #2 (-28)\n",
      "player 4: #4 (-48)\n"
     ]
    }
   ],
   "source": [
    "for _, idx, _, scr, place in gym(players)[-N:]:\n",
    "    print(f'player {idx}: #{place+1} ({scr})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
